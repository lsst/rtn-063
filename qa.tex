\section{Data Product Quality Assurance} \label{sec:qa}

During PDR2, the Verification and Validation Team was responsible 
for identifying problems and bugs in the pipelines and data products. 
Some science quality plots and discussion follows below.

\subsection{Production system errors and retries}

First, however, we note that the Production pilot and co-pilot, 
were responsible for identifying production errors due to things 
like memory-overflow, wall clock time limit exceeded, 
(temporary) communication error between SLURM, PanDA, the butler or other 
production system components.  Once errors were
identified, experts from the relevant team were contacted if necessary.
If possible to rerun a job, either without changes, or with an
increased allocation of memory or wall clock time limit, the pilot and
or co-pilot took this action.

The PanDA system has a built-in retry mechanism, set to 3 retries.  This
enables production to proceed without intervention in the case of
temporary network or process communication issues. However,
currently, the retry mechanism does not automatically increase memory
or wallclock run time -- that must be done by the pilots by increasing
a memory request in the requestMemory.yaml for a failed pipetask or
by moving the job to a different queue with an increased wallclock time
(which can also be achieved by increasing requested memory above 18GB which
assigns it into the extra hi-mem queue.

\subsection{Science Pipeline Q/A and issue management}

Normally, following completion of step7 during a DRP, Q/A plots are made,
and metrics are calculated giving a large variety of determinations of
the science quality of the data outputs.

For HSC PDR2, some of these metrics and plots were generated prior to 
the completion of steps 4, 5 and 6.

The fgcm step2c produces 'local' outputs, but does not currently upload them 
into a butler, so they must be captured before the local worker scrach space where they were
generated disappears.  This was done by examining a 2nd local run of step2c and the 
photometric quality of the
data was verified by the fgcm developer.
 
Following the running of step3, scripts from the analysis tools software product
was run on the outputs generated during step3, including deepCoadds, outputTables and other
datasetTypes. The version of analysis tools run is not currently part of the v24 software distribution,
but is compatible with the outputs produced.

Additionally, a few specialized Q/A outputs were generated using standard plotting and display
tools such as DS9, and python's matplotlib.  These may be candidates for inclusion in future 
Analysis Tools.

The initial run of Analysis tools occurred on a version of the step3 outputs which were not
quite complete, as the issue with dynamic sky was still being fixed.  
After the fix was complete,  the butler chain collection with switch --prepend was used to
prepend the corrected objectTable outputs onto the existing step3 collection chain.
Proper use of the --find-first switch when searching a collection of outputs in the butler then
enables one to extract a unique and complete dataset from a collection and disregard earlier incorrect or 
incomplete processings.

There were there main phases of V\&V work:

\begin{itemize}
\item A period of analysis using a “pilot run” before the start of production, which ran a single
tract through all steps of the pipeline, using the codebase planned for the release.
\item Spot checks during processing, and follow-up of unexpected errors or failed tasks.
\end{itemize}

During these main phases, the V\&V team made extensive use of the plotting capabilities in
analysis\_drp along with adding new diagnostic plots. Much of the analysis was performed by writing
notebooks to test out new diagnostics for data products that were recently added to the pipelines.
The team also drew on experience from many prior processings (particularly of Hypersuprime-cam) to
quickly distinguish ``known'' problems from new problems.

Here are some sample Quality Analysis Figures either selected from the 
standard V\&V Analysis plots, or generated from the PDR2 step3 (coadd) 
output images and tables.

\begin{itemize}

 \item Figure \ref{fig:footprint0} shows a close up of a figure derived from the healSparsePropertyMap for 
coadded sky noise of the footprint, scaled to reflect point source detection limit in each 
healpix pixel of the sky.

 \begin{figure}[h]
 \includegraphics[width=0.9\textwidth]{r-band-cosmos-pdr2.png}
	 \caption{Closeup of PDR2 footprint depth near the COSMOS UDEEP tract.  \label{fig:footprint0}}
 \end{figure}

\item Figure \ref{fig:colorcolor} shows a color-color plot of the UDEEP COSMOS tract 9813 with star/galaxy
separation.  The tightness of the stellar locus and separation from the more spread out cloud of extended
objects indicates successful processing of this tract in at least some respects.

 \begin{figure}[h]
 \includegraphics[width=0.9\textwidth]{colorColor9813.png}
	 \caption{Color color plot of objects masured in UDEEP COSMOS tract 9813 with star/galaxy separation (N=300).  \label{fig:colorcolor}}
 \end{figure}

\item Figure \ref{fig:coadd} shows a side-by-side deepCoadd image of the center of one patch (42) of one tract
(9813) in the i-band.  On the left is the weekly $\rm w_2023_23$ reprocessing the coadd which combines about
N=33 visits.  On the right is the HSC PDR2 full UDEEP coadd of the same area of sky combining approximately
N=300 visits.   While the objects visible by eye are similar, the sky noise is significantly smaller on the
right, and so the S/N is higher for objects in the UDEEP coadd (and the magnitude errors are smaller).

 \begin{figure}[h]
 \includegraphics[width=0.9\textwidth]{sidebyside9813p42bi.png}
	 \caption{N=33 patch coadd (left) and N=300 patch coad (right).  While the visible objects are similar, the coadd to the right has less sky noise due to the deeper coadd, thus the S/N of detected objects is higher.  \label{fig:coadd}}
 \end{figure}


\item Figure \ref{fig:s2n} shows the point source S/N vs. magitude for objects from Figure \ref{fig:coadd}.  In red are the weekly (shallower) coadd objects and in green are the deeper PDR2 full depth objects.   The
magnitude for objects in the deeper coadd for objects of the same S/N extends a significant 
fraction of a magnitude fainter.

 \begin{figure}[h]
 \includegraphics[width=0.8\textwidth,natwidth=600,natheight=600]{redgreen31.5.png}
	 \caption{N=33 patch coadd S/N vs. PSF mag (red) and N=300 patch coadd (green).  With the deeper coadd, the S/N for objects of the same magnitude is about 2x higher.  \label{fig:s2n}}
 \end{figure}

\item Figures \ref{fig:deblend1}, \ref{fig:deblend2} (full patch) show that the deepest coadds
don't always detect and deblend the objects in the same way as shallower coadds.  In some cases, the
shallower coadd has more complete detection and deblending than the very deep coadds.  

 \begin{figure}[h]
 \includegraphics[width=0.9\textwidth]{wobjects.png}
	 \caption{N=33 patch coadd (left) and N=300 patch coad (right).  Here the deblending or detection of objects in the very deep coadd misses some objects in the wings of bright central galaxies or bright stars.  \label{fig:deblend1}}
 \end{figure}

 \begin{figure}[h]
 \includegraphics[width=0.9\textwidth]{full.png}
	 \caption{N=33 patch coadd (left) and N=300 patch coad (right).  Full patch 42 from tract 9813 i-band shown. Here the deblending or detection of objects in the very deep coadd misses some objects in the wings of bright central galaxies or bright stars.  \label{fig:deblend2}}
 \end{figure}

\end{itemize}

A recent finding of the V\&V team was noting an area of the PDR2 footprint where WIDE and DEEP tracts 
overlapped which had a 'ring' of missing data where there was data present in other processings of HSC PDR2.
This was eventually tracked down to a subtle issue involving the presence or absence of narrow band
exposures in the DEEP or WIDE data respectively and behavior of the pipeline which required the
presence all bands.  See \jira{DM-40361} for details -- this behavior will be addressed in future releases
of the pipeline.
